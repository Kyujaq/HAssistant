services:
  # Disabled old ollama service - using ollama-chat and ollama-vision instead
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: hassistant-ollama
  #   runtime: nvidia
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ['0', '1']  # Both GTX 1080 Ti and GTX 1070
  #             capabilities: [gpu]
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=all
  #     - OLLAMA_HOST=0.0.0.0:11434
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ./ollama:/root/.ollama  # Persistent model storage
  #     - /home/qjaq/assistant/models:/models:ro  # Read-only access to existing models
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s
  #   networks:
  #     - ha_network

  # Wyoming Whisper STT (Speech-to-Text) - GPU Accelerated with CUDA/cuDNN support
  whisper:
    image: slackr31337/wyoming-whisper-gpu:latest
    container_name: hassistant-whisper
    runtime: nvidia
    command: --model small --language en --uri 'tcp://0.0.0.0:10300' --data-dir /data --device cuda
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              device_ids: ['1']  # GPU 1 → GTX 1070 (lighter model, good for STT)
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
    volumes:
      - ./whisper_data:/data
    ports:
      - "10300:10300"
    restart: unless-stopped
    networks:
      - ha_network

  # Wyoming Piper TTS (Text-to-Speech) - GLaDOS voice - GPU Accelerated
  piper-glados:
    image: rhasspy/wyoming-piper:latest
    container_name: hassistant-piper-glados
    runtime: nvidia
    command: --voice en_US-glados-medium --uri 'tcp://0.0.0.0:10200' --data-dir /data --piper /usr/share/piper/piper
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              device_ids: ['1']  # GPU 1 → GTX 1070 (share with Whisper)
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
    volumes:
      - ./piper_data:/data
    ports:
      - "10200:10200"
    restart: unless-stopped
    networks:
      - ha_network

  # Home Assistant
  homeassistant:
    image: ghcr.io/home-assistant/home-assistant:stable
    container_name: hassistant-homeassistant
    volumes:
      - /home/qjaq/assistant/data/ha_config:/config
      - /etc/localtime:/etc/localtime:ro
    ports:
      - "8123:8123"
    restart: unless-stopped
    privileged: true
    networks:
      - ha_network

  # PostgreSQL with pgvector for Letta memory
  postgres:
    image: pgvector/pgvector:pg15
    container_name: hassistant-postgres
    environment:
      - POSTGRES_DB=hassistant
      - POSTGRES_USER=hassistant
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-CHANGE_ME_STRONG_PASSWORD_REQUIRED}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts:/docker-entrypoint-initdb.d:ro
    ports:
      - "5433:5432"  # Use 5433 to avoid conflict with /assistant postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hassistant -d hassistant"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ha_network

  # Redis for session cache and ephemeral data
  redis:
    image: redis:7-alpine
    container_name: hassistant-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-CHANGE_ME_STRONG_PASSWORD_REQUIRED}
    volumes:
      - redis_data:/data
    ports:
      - "6380:6379"  # Use 6380 to avoid conflict with /assistant redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-CHANGE_ME_STRONG_PASSWORD_REQUIRED}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - ha_network

  # Letta Bridge API
  letta-bridge:
    build: ./services/letta-bridge
    container_name: hassistant-letta-bridge
    env_file: .env
    restart: unless-stopped
    ports:
      - "8081:8081"  # Fixed: Map to correct internal port
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "-H", "x-api-key: ${BRIDGE_API_KEY:-dev-key}", "http://localhost:8081/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ha_network

  # Qwen-Agent for AI orchestration
  qwen-agent:
    build:
      context: ./services/qwen-agent
      dockerfile: Dockerfile
    container_name: hassistant-qwen-agent
    env_file: .env
    depends_on:
      - letta-bridge
    restart: unless-stopped
    networks:
      - ha_network
    # Optional: mount your data/tools/configs
    volumes:
      - ./agent_data:/data

  # GLaDOS Orchestrator - Routes queries between Qwen (brain) and Hermes (personality)
  glados-orchestrator:
    build:
      context: ./services/glados-orchestrator
      dockerfile: Dockerfile
    container_name: hassistant-glados-orchestrator
    environment:
      - OLLAMA_BASE_URL=http://ollama-chat:11434
      - QWEN_MODEL=qwen3:4b-instruct-2507-q4_K_M
      - HERMES_MODEL=glados-hermes3
      - LETTA_BRIDGE_URL=http://hassistant-letta-bridge:8081
      - LETTA_API_KEY=${BRIDGE_API_KEY:-dev-key}
      - PORT=8082
    ports:
      - "8082:8082"
    depends_on:
      - ollama-chat
      - letta-bridge
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ha_network

  # ---- Vision Gateway (CPU heavy, light GPU use unless you enable GPU OCR) ----
  vision-gateway:
    build:
      context: ./services/vision-gateway
      dockerfile: Dockerfile
    container_name: vision-gateway
    privileged: true  # Required for V4L2 device access
    environment:
      # HA push
      - HA_BASE_URL=http://homeassistant:8123
      - HA_TOKEN=${HA_TOKEN}
      # VL endpoint (1070 / Ollama-vision)
      - OLLAMA_VISION_BASE=http://ollama-vision:11434
      - OLLAMA_VISION_MODEL=qwen2.5vl:7b
      # Direct HDMI capture from UGREEN dongle
      - HDMI_ENABLED=true
      - HDMI_DEVICE=/dev/video2
      - HDMI_WIDTH=1920
      - HDMI_HEIGHT=1080
      - HDMI_CAP_FPS=12
      - HDMI_FORCE_MJPG=false
      # scan resolution
      #- SCAN_WIDTH=960
      #- SCAN_HEIGHT=540
      - MATCH_EVERY_N=2  
      # Motion & debounce
      - MOTION_THRESHOLD=0.015
      - COOLDOWN_SECONDS=8
      # Anchor-based detection configuration
      - OCR_MODE=anchor_based  # anchor_based or full_screen
      - ANCHOR_KEYWORDS=Accept,Send,Join,Decline  # Action buttons only (removed Meeting,Invite to reduce false positives)
      - CONTEXT_ZONES_ENABLED=true
      - BUTTON_COORDS=45,350,90,114
      - BUTTON_THRESH=0.40
      - PRESSED_THRESH=0.55
      - PRESS_MARGIN=0.04
      - MIN_PRESSED=0.50
      - DISAPPEAR_THRESH=0.35
      - DISAPPEAR_FRAMES=3
      - PRESS_TIMEOUT_S=3.0
      - REARM_COOLDOWN=1.5
      - HDMI_RESIZE_LONG=1280

    volumes:
      - ./vision-gateway/cache:/app/cache
      - ./vision-gateway/app/assets:/app/assets:ro   # <-- host ./assets → container /app/assets, read-only
    devices:
      - /dev/video2:/dev/video2  # UGREEN HDMI capture dongle
    ports:
      - "8088:8088"  # Debug UI at http://localhost:8088/debug
    depends_on:
      - homeassistant
    restart: unless-stopped
    networks:
      - ha_network

  # ---- Frigate (webcam motion, snapshots) ----
  frigate:
    image: ghcr.io/blakeblackshear/frigate:stable
    container_name: frigate
    runtime: nvidia
    privileged: true
    shm_size: "512m"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu,video]
              device_ids: ['1']   # GPU 1 → GTX 1070 (shared with vision tasks)
    environment:
      - FRIGATE_RTSP_PASSWORD=${FRIGATE_RTSP_PASSWORD:-CHANGE_ME_FRIGATE_PASSWORD}
      - NVIDIA_VISIBLE_DEVICES=1
    volumes:
      - ./frigate/config:/config
      - /etc/localtime:/etc/localtime:ro
      - ./frigate/media:/media/frigate
    devices:
      - /dev/video0:/dev/video0
      - /dev/video2:/dev/video2

    ports:
      - "5000:5000"     # Frigate UI/API
      - "8554:8554"     # RTSP
      - "8555:8555/tcp" # WebRTC
      - "8555:8555/udp" # WebRTC
      - "1984:1984"     # go2rtc API
    restart: unless-stopped
    networks:
      - ha_network

  # Optional helper to snapshot webcam via Frigate API (no GPU)
  frigate-snapshotper:
    image: curlimages/curl:8.10.1
    container_name: frigate-snapshotper
    command: "sleep infinity"
    networks:
      - ha_network

  # Your ollama containers should already exist:
  # - ollama-chat on GPU0 (11434) with Qwen3-* for chat
  # - ollama-vision on GPU1 (11435->11434 in container) with qwen2.5vl:7b
  # Ensure they're reachable as ollama-chat / ollama-vision or use host IPs.
  
  ollama-chat:
    image: ollama/ollama:latest
    container_name: ollama-chat
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              device_ids: ['0']   # GPU 0 → 1080 Ti
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - NVIDIA_VISIBLE_DEVICES=0
    volumes:
      - ollama_chat_data:/root/.ollama
      - ./ollama/modelfiles:/root/.ollama/modelfiles:ro
      - /home/qjaq/assistant/models:/models:ro
    restart: unless-stopped
    networks:
      - ha_network

  ollama-vision:
    image: ollama/ollama:latest
    container_name: ollama-vision
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              device_ids: ['0']   # GPU 0 → GTX 1080 Ti (11GB - fits 8.6GB model)
    ports:
      - "11435:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - NVIDIA_VISIBLE_DEVICES=1
    volumes:
      - ollama_vision_data:/root/.ollama
      - ./ollama/modelfiles:/root/.ollama/modelfiles:ro
      - /home/qjaq/assistant/models:/models:ro
    restart: unless-stopped
    networks:
      - ha_network
  
   # ---- NEW: Face Recognition Stack ---- #

  # Double Take: Orchestrates face recognition between Frigate and CompreFace
  double-take:
    container_name: double-take
    image: jakowenko/double-take
    restart: unless-stopped
    ports:
      - 3000:3000 # Web UI for Double Take
    volumes:
      - ./double-take-config:/config
      - ./double-take-media:/media
    networks:
      - ha_network

  # CompreFace API: The main API service for face recognition
  compreface-api:
    container_name: compreface-api
    image: exadel/compreface-api:1.1.0
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - compreface_db_storage:/var/lib/postgresql/data
    depends_on:
      compreface-postgres:
        condition: service_healthy
    environment:
      - POSTGRES_USER=${COMPREFACE_POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${COMPREFACE_POSTGRES_PASSWORD:-postgres}
      - POSTGRES_URL=jdbc:postgresql://compreface-postgres:5432/frs
      - JAVA_OPTS=-Xmx4g
    networks:
      - ha_network

  # CompreFace Admin: The UI for managing faces and training the model
  compreface-admin:
    container_name: compreface-admin
    image: exadel/compreface-admin:1.1.0
    restart: unless-stopped
    ports:
      - "81:80" # CompreFace Admin UI will be on port 81
    depends_on:
      - compreface-api
    networks:
      - ha_network

  # CompreFace Core: The actual face detection/recognition ML model
  compreface-core:
    container_name: compreface-core
    image: exadel/compreface-core:1.1.0
    restart: unless-stopped
    environment:
      - ML_PORT=3000
      - SAVE_FACES_TO_DB=true
    # To enable GPU acceleration for CompreFace, uncomment the deploy section below
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    networks:
      - ha_network

  # CompreFace PostgreSQL Database: A dedicated DB for CompreFace
  compreface-postgres:
    container_name: compreface-postgres
    image: postgres:13.1
    restart: unless-stopped
    ports:
      - "5433:5432" # Use port 5433 to avoid conflict with hassistant-postgres
    environment:
      - POSTGRES_USER=${COMPREFACE_POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${COMPREFACE_POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=frs
    volumes:
      - compreface_db_storage:/var/lib/postgresql/data
    networks:
      - ha_network 
  
  # Computer Control Agent (optional, for remote computer automation)
  # Uncomment to enable computer control capabilities
  # computer-control-agent:
  #   build:
  #     context: ./clients
  #     dockerfile: Dockerfile.computer_control
  #   container_name: hassistant-computer-control
  #   environment:
  #     - VISION_GATEWAY_URL=http://vision-gateway:8088
  #     - OLLAMA_URL=http://ollama-chat:11434
  #     - OLLAMA_MODEL=qwen3:4b-instruct-2507-q4_K_M
  #     - HA_URL=http://homeassistant:8123
  #     - HA_TOKEN=${HA_TOKEN}
  #     - CONFIRM_BEFORE_ACTION=true
  #     - MAX_ACTIONS_PER_TASK=50
  #   volumes:
  #     - ./config/computer_control_agent.env:/app/computer_control_agent.env
  #     - /tmp/.X11-unix:/tmp/.X11-unix  # For X11 forwarding
  #   depends_on:
  #     - vision-gateway
  #     - ollama-chat
  #   restart: unless-stopped
  #   networks:
  #     - ha_network



volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_chat_data:
    driver: local
  ollama_vision_data:
    driver: local
    piper_data:
  whisper_data:
  ha_config:
  mosquitto_config:
  mosquitto_data:
  mosquitto_log:
  agent_data:
  compreface_db_storage:
  double-take-config:
  double-take-media:

networks:
  ha_network:
    external: true
    name: assistant_default  # Connect to existing HA network
