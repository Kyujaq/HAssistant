# K80 Vision Integration - Implementation Complete

**Date**: 2025-10-12
**Status**: ‚úÖ Phase 1 & 2 Complete - Ready for Model Download
**GPU**: Tesla K80 (GPU 2, 24GB VRAM)

---

## Summary

The Tesla K80 GPU has been successfully integrated into the vision-gateway service for continuous object detection using GroundingDINO. The system is now ready for Phase 3 testing once model weights are downloaded.

---

## What's Been Completed

### Phase 1: Hardware & Docker Setup ‚úÖ

1. **GPU Recognition**: K80 detected as GPU 2 and GPU 3 (dual-GPU card)
2. **Docker Configuration**:
   - Updated `docker-compose.yml` to allocate GPU 2 to vision-gateway
   - Added `runtime: nvidia` and proper device allocation
   - Fixed nvidia-container-toolkit after driver downgrade to 470/480
3. **CUDA Support**:
   - PyTorch 2.1.0 with CUDA 11.8 support
   - All CUDA runtime libraries bundled in container
   - Verified GPU access from within container

### Phase 2: K80 Preprocessor Module ‚úÖ

1. **Created `app/k80_preprocessor.py`**:
   - `K80Preprocessor` class for GPU-accelerated object detection
   - `SceneTracker` class for intelligent scene change detection
   - Smart triggering logic to reduce Qwen VL calls by ~10x

2. **Integrated with main loop**:
   - K80 detection runs every N frames (configurable via `MATCH_EVERY_N`)
   - Scene change detection triggers Qwen VL only when needed
   - HA events sent on scene changes: `vision.k80_scene_change`
   - Detections stored in `recent_detections` API

3. **Dependencies**:
   - PyTorch 2.1.0 + CUDA 11.8
   - GroundingDINO (git version for PyTorch 2.1 compatibility)
   - transformers 4.36.2 (pinned for compatibility)
   - supervision library for detection utilities

---

## Current Status

### What Works ‚úÖ
- K80 GPU accessible from vision-gateway container
- PyTorch sees all 4 GPUs (GTX 1080 Ti, GTX 1070, 2x K80)
- K80Preprocessor module imports successfully
- HDMI capture running on /dev/video2 @ 1920x1080 10fps
- Template matching still functional as fallback
- Smart scene change detection ready

### What's Needed üîß
- **Model weights**: GroundingDINO model files (~700MB)
- **Enable K80**: Set `K80_ENABLED=true` in docker-compose.yml
- **Testing**: End-to-end validation with real UI detection

---

## Next Steps

### 1. Download Model Weights

Run the provided script:

```bash
cd /home/qjaq/HAssistant/services/vision-gateway
./download_models.sh
```

This will:
- Create `/app/models` directory in container
- Download GroundingDINO model weights (~700MB)
- Download config files
- Verify installation

### 2. Enable K80 Preprocessing

Update `docker-compose.yml`:

```yaml
environment:
  - K80_ENABLED=true  # Change from false to true
```

Restart the service:

```bash
docker compose restart vision-gateway
```

### 3. Verify Operation

Check logs for K80 initialization:

```bash
docker compose logs -f vision-gateway | grep -i k80
```

Expected output:
```
[hdmi] Initializing K80 preprocessor on cuda:2...
INFO:app.k80_preprocessor:Using GPU 2: Tesla K80
INFO:app.k80_preprocessor:GroundingDINO model loaded successfully
[hdmi] K80 preprocessor initialized successfully!
```

### 4. Monitor Performance

Watch for detection logs:
```bash
docker compose logs -f vision-gateway | grep -E "(k80|K80 Detection)"
```

Expected metrics:
- Detection FPS: 5-10 FPS (goal achieved)
- Scene changes: Logged when detected
- Qwen calls: Only on scene changes (10x reduction)

---

## Architecture

### GPU Allocation (Updated)

```
GPU 0 (GTX 1080 Ti - 11GB):  Qwen2.5-VL vision model
GPU 1 (GTX 1070):            Hermes-3 + Whisper + Piper + Frigate
GPU 2 (Tesla K80 - 24GB):    GroundingDINO continuous detection ‚Üê NEW
GPU 3 (Tesla K80 - 24GB):    Reserved for future use
```

### Detection Flow

```
HDMI Capture (1920x1080 @ 10fps)
    ‚Üì
K80: GroundingDINO Detection (every 3rd frame)
    ‚Ä¢ Detect buttons, dialogs, windows
    ‚Ä¢ Extract bounding boxes and labels
    ‚Ä¢ Compute scene similarity
    ‚Üì
Scene Change? (threshold: 0.3)
    ‚Üì Yes
GPU 0: Qwen2.5-VL Deep Analysis
    ‚Ä¢ Semantic understanding
    ‚Ä¢ Context extraction
    ‚Ä¢ Meeting invite detection
    ‚Üì
HA Event: vision.k80_scene_change
```

### Configuration

Environment variables in `docker-compose.yml`:

```yaml
# K80 GPU preprocessing
- K80_ENABLED=false              # Set to true after model download
- K80_DEVICE=cuda:2              # Tesla K80 GPU ID
- K80_BOX_THRESHOLD=0.35         # Bounding box confidence threshold
- K80_TEXT_THRESHOLD=0.25        # Text matching threshold
- K80_SCENE_CHANGE_THRESHOLD=0.3 # Scene similarity threshold (lower = more sensitive)
```

---

## Files Changed

### New Files
- `services/vision-gateway/app/k80_preprocessor.py` - K80 detection module
- `services/vision-gateway/download_models.sh` - Model download script
- `services/vision-gateway/test_k80.py` - Test script
- `docs/implementation/K80_INTEGRATION_COMPLETE.md` - This file

### Modified Files
- `docker-compose.yml` - K80 GPU allocation and env vars
- `services/vision-gateway/Dockerfile` - PyTorch + GroundingDINO
- `services/vision-gateway/app/main.py` - K80 integration in main loop

---

## Testing

### Basic GPU Test

```bash
docker exec vision-gateway python3 -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'K80 accessible: {torch.cuda.get_device_name(2)}')
print(f'Test tensor on K80: {torch.tensor([1.0]).cuda(2).device}')
"
```

Expected output:
```
CUDA available: True
K80 accessible: Tesla K80
Test tensor on K80: cuda:2
```

### Module Import Test

```bash
docker exec vision-gateway python3 -c "
from app.k80_preprocessor import K80Preprocessor, SceneTracker
print('‚úì K80Preprocessor imported successfully')
"
```

### Full Detection Test (after model download)

```bash
# Enable K80
docker compose restart vision-gateway

# Watch logs
docker compose logs -f vision-gateway | grep k80
```

---

## Performance Targets

| Metric | Target | Status |
|--------|--------|--------|
| K80 Detection FPS | 5-10 FPS | ‚è≥ Pending model download |
| Frame processing time | ~100ms | ‚è≥ Pending model download |
| Scene change detection | <10ms | ‚úÖ Implemented |
| Qwen call reduction | 10x | ‚è≥ Pending validation |
| UI element coverage | Any element | ‚è≥ Pending validation |

---

## Troubleshooting

### Model Loading Fails

**Error**: `FileNotFoundError: Model files not found`

**Solution**: Run `./download_models.sh` to download model weights

### K80 Not Detected

**Error**: `GPU 2 not available`

**Solution**:
```bash
# Check nvidia-smi shows 4 GPUs
nvidia-smi

# Reinstall nvidia-container-toolkit if needed
sudo apt-get install --reinstall nvidia-container-toolkit
sudo systemctl restart docker
```

### CUDA Out of Memory

**Error**: `CUDA out of memory`

**Solution**: K80 has 24GB - this shouldn't happen. Check if other processes are using GPU 2:
```bash
nvidia-smi | grep "GPU 2"
```

### Detection Too Slow

If detection FPS < 5:
- Lower image resolution (already at 1920x1080)
- Increase `MATCH_EVERY_N` to run detection less frequently
- Check GPU utilization: `nvidia-smi dmon -s u -i 2`

### Too Many Qwen Calls

If scene changes trigger too often:
- Increase `K80_SCENE_CHANGE_THRESHOLD` (0.3 ‚Üí 0.4 or 0.5)
- This makes scene tracker less sensitive

---

## API Endpoints

### Get Latest Detections

```bash
curl http://localhost:8088/api/detections
```

Response includes K80 detections when enabled:
```json
[
  {
    "timestamp": 1697123456.789,
    "result": {
      "k80_detections": [
        {
          "label": "send button",
          "bbox": [100, 200, 80, 40],
          "confidence": 0.87
        }
      ],
      "vl": { ... },
      "detection_mode": "k80_groundingdino"
    },
    "frame_b64": "..."
  }
]
```

### Health Check

```bash
curl http://localhost:8088/healthz
```

---

## Future Enhancements

### Phase 3: OCR Integration
- K80 for text detection (EAST/CRAFT)
- Extract text from UI elements
- Voice: "Click the button that says X"

### Phase 4: Action History
- Record all detected elements
- Build UI state graph
- Predict likely next actions

### Phase 5: Vision Memory
- Store UI layouts in Letta
- Learn application patterns
- Faster detection of known UIs

---

## Success Criteria

| Phase | Criteria | Status |
|-------|----------|--------|
| Phase 1 | K80 visible in nvidia-smi from container | ‚úÖ Complete |
| Phase 2 | GroundingDINO integration implemented | ‚úÖ Complete |
| Phase 3 | Detection at 5+ FPS | ‚è≥ Pending model |
| Phase 4 | 10x Qwen call reduction | ‚è≥ Pending validation |
| Phase 5 | Voice "Click X" end-to-end | ‚è≥ Future work |

---

## Notes

- Driver downgraded to 470/480 for K80 compatibility (from 550+)
- PyTorch 2.1.0 + CUDA 11.8 compatible with driver 470
- nvidia-container-toolkit reinstalled after driver downgrade
- K80 is dual-GPU card (appears as GPU 2 and GPU 3)
- Only GPU 2 allocated to vision-gateway (GPU 3 reserved)
- Template matching remains as fallback if K80 disabled

---

**Last Updated**: 2025-10-12 04:30 AM EDT
**Next Milestone**: Download model weights and enable K80_ENABLED=true
