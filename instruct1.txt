ðŸ§­ Instructions for Claude (copy/paste)

Create a new folder letta_bridge/ and place these files exactly as specified. Then follow the â€œRunâ€ and â€œIntegrate with HAâ€ steps.

1) Files to create
letta_bridge/main.py
import os
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Literal

import asyncpg
import aioredis
import uvicorn
from fastapi import FastAPI, HTTPException, Depends, Header, Query
from pydantic import BaseModel, Field
import numpy as np

# --------------------
# ENV & CONFIG
# --------------------
PG_DSN = os.getenv("LETTA_PG_URI", "postgresql://letta:pass@postgres:5432/letta")
REDIS_URL = os.getenv("LETTA_REDIS_URL", "redis://:pass@redis:6379/0")
API_KEY = os.getenv("BRIDGE_API_KEY", "dev-key")  # set a real key in prod
EMBED_DIM = int(os.getenv("EMBED_DIM", "384"))    # match your pgvector dim
DAILY_BRIEF_WINDOW_HOURS = int(os.getenv("DAILY_BRIEF_WINDOW_HOURS", "24"))

# --------------------
# FastAPI
# --------------------
app = FastAPI(title="Letta Bridge", version="0.1.0")

async def get_pg():
    pool = await asyncpg.create_pool(PG_DSN, min_size=1, max_size=5)
    try:
        yield pool
    finally:
        await pool.close()

async def get_redis():
    redis = await aioredis.from_url(REDIS_URL, decode_responses=True)
    try:
        yield redis
    finally:
        await redis.close()

async def auth(x_api_key: Optional[str] = Header(default=None)):
    if API_KEY and x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Unauthorized")
    return True

# --------------------
# Schemas
# --------------------
Tier = Literal["short", "medium", "long", "permanent"]
MemType = Literal["fact","event","task","preference","insight","entity","note"]

class MemoryIn(BaseModel):
    type: MemType = "event"
    title: str
    content: str
    tags: List[str] = Field(default_factory=list)
    source: List[str] = Field(default_factory=list)
    confidence: float = 0.7
    tier: Tier = "short"
    ttl_days: Optional[int] = 2
    pin: bool = False
    meta: dict = Field(default_factory=dict)
    generate_embedding: bool = True

class PinIn(BaseModel):
    id: str
    pin: bool = True

class ForgetIn(BaseModel):
    id: str
    reason: Optional[str] = None

class SearchOutItem(BaseModel):
    id: str
    title: str
    preview: str
    type: str
    tier: Tier
    confidence: float
    score: float
    created_at: str
    tags: List[str] = []
    source: List[str] = []

# --------------------
# Embeddings (placeholder)
# Replace with your real model (e.g., sentence-transformers)
# --------------------
def fake_embed(text: str, dim: int = EMBED_DIM) -> List[float]:
    # DO NOT use in production; deterministic pseudo-embedding for scaffolding
    rng = np.random.default_rng(abs(hash(text)) % (2**32))
    v = rng.standard_normal(dim)
    v = v / (np.linalg.norm(v) + 1e-9)
    return v.astype(np.float32).tolist()

# --------------------
# Routes
# --------------------
@app.get("/healthz")
async def healthz():
    return {"status": "ok", "time": datetime.now(timezone.utc).isoformat()}

@app.post("/memory/add")
async def add_memory(
    body: MemoryIn,
    _=Depends(auth),
    pg=Depends(get_pg),
    redis=Depends(get_redis),
):
    now = datetime.now(timezone.utc)
    async with pg.acquire() as conn:
        async with conn.transaction():
            mem_id = await conn.fetchval(
                """
                INSERT INTO memory_blocks
                  (id, type, title, content, tags, source, confidence, created_at, last_used_at, tier, ttl_days, pin, meta)
                VALUES
                  (concat('mem_', to_char($1, 'YYYYMMDD_HH24MISS'), '_', substr(md5(random()::text),1,6)),
                   $2, $3, $4, $5, $6, $7, $1, $1, $8, $9, $10, $11)
                RETURNING id
                """,
                now, body.type, body.title, body.content, body.tags, body.source,
                body.confidence, body.tier, body.ttl_days, body.pin, body.meta
            )

            if body.generate_embedding:
                emb = fake_embed(body.title + "\n" + body.content, EMBED_DIM)
                await conn.execute(
                    """
                    INSERT INTO memory_embeddings (memory_id, embedding)
                    VALUES ($1, $2)
                    ON CONFLICT (memory_id) DO UPDATE SET embedding = EXCLUDED.embedding
                    """,
                    mem_id, emb
                )

    # small ephemeral marker in Redis (optional)
    await redis.setex(f"cooldown:mem_add:{mem_id}", 60, "1")
    return {"status": "ok", "id": mem_id}

@app.post("/memory/pin")
async def memory_pin(body: PinIn, _=Depends(auth), pg=Depends(get_pg)):
    async with pg.acquire() as conn:
        rec = await conn.fetchrow("SELECT id FROM memory_blocks WHERE id=$1", body.id)
        if not rec:
            raise HTTPException(404, "Memory not found")
        await conn.execute("UPDATE memory_blocks SET pin=$1 WHERE id=$2", body.pin, body.id)
    return {"status":"ok","id":body.id,"pinned":body.pin}

@app.post("/memory/forget")
async def memory_forget(body: ForgetIn, _=Depends(auth), pg=Depends(get_pg)):
    async with pg.acquire() as conn:
        rec = await conn.fetchrow("SELECT id FROM memory_blocks WHERE id=$1", body.id)
        if not rec:
            raise HTTPException(404, "Memory not found")
        await conn.execute(
            "UPDATE memory_blocks SET tier='short', ttl_days=2, pin=false WHERE id=$1",
            body.id
        )
    return {"status":"ok","id":body.id,"tier":"short"}

@app.get("/memory/search", response_model=List[SearchOutItem])
async def memory_search(
    q: str = Query(..., description="Text query"),
    k: int = 8,
    tiers: Optional[str] = Query(None, description="comma list e.g. short,medium,long,permanent"),
    types: Optional[str] = Query(None, description="comma list e.g. event,fact,insight"),
    _=Depends(auth),
    pg=Depends(get_pg)
):
    tiers_list = [t.strip() for t in tiers.split(",")] if tiers else None
    types_list = [t.strip() for t in types.split(",")] if types else None

    # text match + optional vector
    async with pg.acquire() as conn:
        # vector part
        emb = fake_embed(q, EMBED_DIM)
        filters = []
        params = [emb]
        if tiers_list:
            filters.append(f"tier = ANY(${len(params)+1})")
            params.append(tiers_list)
        if types_list:
            filters.append(f"type = ANY(${len(params)+1})")
            params.append(types_list)
        where = ("WHERE " + " AND ".join(filters)) if filters else ""

        rows = await conn.fetch(
            f"""
            SELECT mb.id, mb.title, left(mb.content, 200) AS preview, mb.type, mb.tier,
                   mb.confidence, mb.created_at, mb.tags, mb.source,
                   1 - (me.embedding <=> $1::vector) AS score
            FROM memory_embeddings me
            JOIN memory_blocks mb ON mb.id = me.memory_id
            {where}
            ORDER BY score DESC
            LIMIT {k}
            """,
            *params
        )
    return [
        SearchOutItem(
            id=r["id"], title=r["title"], preview=r["preview"], type=r["type"],
            tier=r["tier"], confidence=r["confidence"],
            score=float(r["score"]), created_at=r["created_at"].isoformat(),
            tags=r["tags"] or [], source=r["source"] or []
        )
        for r in rows
    ]

@app.get("/daily_brief")
async def daily_brief(
    _=Depends(auth),
    pg=Depends(get_pg),
):
    since = datetime.now(timezone.utc) - timedelta(hours=DAILY_BRIEF_WINDOW_HOURS)
    async with pg.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT id, title, left(content, 240) AS preview, type, tier, created_at
            FROM memory_blocks
            WHERE created_at >= $1
              AND (type = 'insight' OR tier IN ('medium','long','permanent'))
            ORDER BY created_at DESC
            LIMIT 20
            """,
            since
        )
    return {
        "since": since.isoformat(),
        "items": [
            {
                "id": r["id"], "title": r["title"], "preview": r["preview"],
                "type": r["type"], "tier": r["tier"],
                "created_at": r["created_at"].isoformat()
            } for r in rows
        ]
    }

@app.get("/metrics")
async def metrics():
    return {"uptime": "ok"}  # stub; add real metrics later

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.getenv("PORT", "8081")), reload=False)

letta_bridge/requirements.txt
fastapi==0.114.2
uvicorn[standard]==0.30.6
asyncpg==0.29.0
redis==5.0.7
numpy==2.1.1

letta_bridge/Dockerfile
FROM python:3.11-slim
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
RUN apt-get update && apt-get install -y --no-install-recommends build-essential && rm -rf /var/lib/apt/lists/*
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY main.py .
EXPOSE 8081
ENV PORT=8081
CMD ["python", "main.py"]

.env (at repo root or compose folder)
BRIDGE_API_KEY=change-me
LETTA_PG_URI=postgresql://letta:pass@postgres:5432/letta
LETTA_REDIS_URL=redis://:pass@redis:6379/0
EMBED_DIM=384
DAILY_BRIEF_WINDOW_HOURS=24

docker-compose.yml (add service)
services:
  letta-bridge:
    build: ./letta_bridge
    env_file: .env
    restart: unless-stopped
    ports:
      - "8081:8081"
    depends_on:
      - postgres
      - redis
    networks:
      - default


Ensure your existing postgres and redis services are in the same compose and named postgres / redis (or update DSNs accordingly). If youâ€™ve exposed Postgres at 5433 externally, the internal service port remains 5432 in Docker.

2) Run
docker compose build letta-bridge
docker compose up -d letta-bridge
curl -H "x-api-key: change-me" http://localhost:8081/healthz

3) Home Assistant integration

configuration.yaml

rest_command:
  letta_add_memory:
    url: "http://letta-bridge:8081/memory/add"
    method: POST
    headers:
      x-api-key: "change-me"
      content-type: "application/json"
    payload: >
      {
        "type": "{{ type|default('event') }}",
        "title": "{{ title }}",
        "content": "{{ content }}",
        "tags": {{ tags|default([]) }},
        "source": {{ source|default([]) }},
        "confidence": {{ confidence|default(0.7) }},
        "tier": "{{ tier|default('short') }}",
        "ttl_days": {{ ttl|default(2) }},
        "pin": {{ pin|default(false) }},
        "generate_embedding": {{ generate_embedding|default(true) }}
      }

sensor:
  - platform: rest
    name: daily_brief
    resource: "http://letta-bridge:8081/daily_brief"
    method: GET
    headers:
      x-api-key: "change-me"
    scan_interval: 900
    value_template: "{{ value_json.items | length }}"
    json_attributes:
      - since
      - items


Example automation (push event â†’ memory):

automation:
  - id: vision_invite_seen
    alias: Vision Invite â†’ Memory
    trigger:
      - platform: state
        entity_id: sensor.meeting_state
        to: "invite_pending"
    action:
      - service: rest_command.letta_add_memory
        data:
          title: "Meeting invite detected"
          content: "UI shows an invite with Accept/Decline."
          tags: '["calendar","invite"]'
          source: '["ha://sensor/meeting_state"]'
          confidence: 0.85
          tier: "short"
